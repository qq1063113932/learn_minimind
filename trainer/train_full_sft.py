import os
import sys

# ğŸ“š Pythonæ¨¡å—ç³»ç»Ÿå’Œè·¯å¾„ç®¡ç†
__package__ = "trainer"
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

import argparse  # å‘½ä»¤è¡Œå‚æ•°è§£æ
import time      # æ—¶é—´æµ‹é‡
import warnings  # è­¦å‘Šæ§åˆ¶
import torch     # PyTorchæ·±åº¦å­¦ä¹ æ¡†æ¶
import torch.distributed as dist  # åˆ†å¸ƒå¼è®­ç»ƒ
from contextlib import nullcontext  # ä¸Šä¸‹æ–‡ç®¡ç†å™¨
from torch import optim, nn         # ä¼˜åŒ–å™¨å’Œç¥ç»ç½‘ç»œ
from torch.nn.parallel import DistributedDataParallel  # åˆ†å¸ƒå¼å¹¶è¡Œ
from torch.utils.data import DataLoader, DistributedSampler  # æ•°æ®åŠ è½½

from model.myminimind import MokioMindConfig   # æ¨¡å‹é…ç½®
from dataset.lm_dataset import SFTDataset          # SFTæ•°æ®é›†
from trainer.trainer_utils import (                # è®­ç»ƒå·¥å…·
    get_lr, Logger, is_main_process, lm_checkpoint, 
    init_distributed_mode, setup_seed, init_model, SkipBatchSampler
)

warnings.filterwarnings('ignore')

def train_epoch(epoch,loader,iters,start_step=0,wandb=None):
    loss_fct=nn.CrossEntropyLoss(reduction='none')
    start_time=time.time()
    
    for step,(X,Y,loss_mask) in enumerate(loader,start=start_step+1):
        X=X.to(args.device)
        Y=Y.to(args.device)
        loss_mask=loss_mask.to(args.device)
        
        # åŠ¨æ€è°ƒæ•´å­¦ä¹ ç‡
        lr=get_lr(epoch*iters+step,args.epochs*iters,args.learning_rate)
        for param_group in optimizer.param_groups:
            param_group['lr']=lr
        
        with autocast_ctx:
            # å‰å‘ä¼ æ’­
            res=model(X)

            # 1. logits é¢„æµ‹çš„æ˜¯ä¸‹ä¸€ä½ï¼Œæ‰€ä»¥å»æ‰æœ€åä¸€ä¸ªé¢„æµ‹
            shift_logits = res.logits[:, :-1, :].contiguous()
            # 2. æ ‡ç­¾æ˜¯ç›®æ ‡ï¼Œæ‰€ä»¥å»æ‰ç¬¬ä¸€ä¸ªèµ·å§‹ä½
            shift_labels = Y[:, 1:].contiguous()
            # 3. æ©ç ä¹Ÿè¦åŒæ­¥å»æ‰ç¬¬ä¸€ä¸ªä½ç½®
            shift_mask = loss_mask[:, 1:].contiguous()
            
            # æŸå¤±è®¡ç®—
            raw_loss = loss_fct(
                shift_logits.view(-1, shift_logits.size(-1)), 
                shift_labels.view(-1)
            )

            # æŠŠ loss é‡æ–° view å› [Batch, Seq-1] çš„å½¢çŠ¶ä»¥ä¾¿å’Œ mask ç›¸ä¹˜
            loss = (loss * shift_mask).sum() / (shift_mask.sum() + 1e-9)
            
            loss= (loss * loss_mask).sum() / loss_mask.sum()
            
            # loss+=res.aux_loss
            
            loss=loss/args.acculation_steps
            
        scaler.scale(loss).backward()
        
        if (step+1)%args.accumulation_steps==0:
            scaler.unscale_(optimizer)
            
            torch.nn.utils.clip_grad_norm_(model.parameters(),args.grad_clip)
            
            scaler.step(optimizer)
            scaler.update()
            
            optimizer.zero_grad(set_to_none=True)
            
        if step % args.log_interval == 0 or step == iters - 1:
            spend_time = time.time() - start_time
            current_loss = loss.item() * args.accumulation_steps  # æ¢å¤çœŸå®æŸå¤±å€¼
            current_lr = optimizer.param_groups[-1]['lr']
            eta_min = spend_time / (step + 1) * iters // 60 - spend_time // 60
            
            Logger(f'Epoch:[{epoch+1}/{args.epochs}]({step}/{iters}) loss:{current_loss:.6f} lr:{current_lr:.12f} epoch_Time:{eta_min}min:')
            
            # è®°å½•åˆ°å®éªŒè·Ÿè¸ªç³»ç»Ÿ
            if wandb: 
                wandb.log({"loss": current_loss, "lr": current_lr, "epoch_Time": eta_min})

        # ğŸ“š SFTæ¨¡å‹æ£€æŸ¥ç‚¹ä¿å­˜
        if (step % args.save_interval == 0 or step == iters - 1) and is_main_process():
            model.eval()  # åˆ‡æ¢åˆ°è¯„ä¼°æ¨¡å¼
            
            # æ„å»ºSFTæ¨¡å‹ä¿å­˜è·¯å¾„
            moe_suffix = '_moe' if lm_config.use_moe else ''
            ckp = f'{args.save_dir}/{args.save_weight}_{lm_config.hidden_size}{moe_suffix}.pth'
            
            # å¤„ç†åˆ†å¸ƒå¼æ¨¡å‹çš„çŠ¶æ€å­—å…¸
            if isinstance(model, torch.nn.parallel.DistributedDataParallel):
                state_dict = model.module.state_dict()
            else:
                state_dict = model.state_dict()
            
            # åŠç²¾åº¦ä¿å­˜èŠ‚çœç©ºé—´
            state_dict = {k: v.half() for k, v in state_dict.items()}
            torch.save(state_dict, ckp)
            # ä¿å­˜å®Œæ•´è®­ç»ƒçŠ¶æ€
            lm_checkpoint(lm_config, weight=args.save_weight, model=model, optimizer=optimizer, 
                         epoch=epoch, step=step, wandb=wandb, save_dir='../checkpoints', scaler=scaler)
            model.train()  # æ¢å¤è®­ç»ƒæ¨¡å¼
            
if __name__ == "__main__":
    """
    SFTä¸»å‡½æ•°ï¼šç›‘ç£å¾®è°ƒè„šæœ¬çš„å…¥å£ç‚¹
    
    ğŸ“š SFTä¸é¢„è®­ç»ƒçš„å‚æ•°å·®å¼‚ï¼š
    - å­¦ä¹ ç‡æ›´å°ï¼š5e-7 vs 5e-4ï¼ˆé¢„è®­ç»ƒï¼‰
    - è®­ç»ƒè½®æ•°è¾ƒå°‘ï¼š2è½® vs å¤šè½®
    - batch_sizeå¯ä»¥æ›´å°ï¼šå·²æœ‰åŸºç¡€èƒ½åŠ›ï¼Œä¸éœ€è¦å¤§batch
    - ç´¯ç§¯æ­¥æ•°é€šå¸¸ä¸º1ï¼šSFTæ•°æ®è´¨é‡é«˜ï¼Œä¸éœ€è¦å¤ªå¤šç´¯ç§¯
    """
    
    parser = argparse.ArgumentParser(description="MiniMind Full SFT")
    
    # ========== åŸºç¡€è®­ç»ƒå‚æ•° ==========
    parser.add_argument("--save_dir", type=str, default="../out", 
                       help="æ¨¡å‹ä¿å­˜ç›®å½•")
    parser.add_argument('--save_weight', default='full_sft', type=str, 
                       help="ä¿å­˜æƒé‡çš„å‰ç¼€å")
    parser.add_argument("--epochs", type=int, default=2, 
                       help="è®­ç»ƒè½®æ•°ï¼ˆSFTé€šå¸¸2-5è½®å³å¯ï¼‰")
    parser.add_argument("--batch_size", type=int, default=16, 
                       help="batch sizeï¼ˆSFTå¯ä»¥ä½¿ç”¨è¾ƒå°çš„batchï¼‰")
    
    # ğŸ“š SFTå­¦ä¹ ç‡è®¾ç½®çŸ¥è¯†ç‚¹
    # SFTå­¦ä¹ ç‡é€šå¸¸æ¯”é¢„è®­ç»ƒå°1-2ä¸ªæ•°é‡çº§
    # å› ä¸ºæ¨¡å‹å·²ç»æœ‰äº†åŸºç¡€èƒ½åŠ›ï¼Œåªéœ€è¦å¾®è°ƒ
    parser.add_argument("--learning_rate", type=float, default=5e-7, 
                       help="åˆå§‹å­¦ä¹ ç‡ï¼ˆæ¯”é¢„è®­ç»ƒå°å¾ˆå¤šï¼‰")
    
    # ========== ç¡¬ä»¶é…ç½® ==========
    parser.add_argument("--device", type=str, 
                       default="cuda:0" if torch.cuda.is_available() else "cpu", 
                       help="è®­ç»ƒè®¾å¤‡")
    parser.add_argument("--dtype", type=str, default="bfloat16", 
                       help="æ··åˆç²¾åº¦ç±»å‹")
    parser.add_argument("--num_workers", type=int, default=1, 
                       help="æ•°æ®åŠ è½½çº¿ç¨‹æ•°")
    
    # ========== è®­ç»ƒç­–ç•¥ ==========
    # ğŸ“š SFTæ¢¯åº¦ç´¯ç§¯çŸ¥è¯†ç‚¹
    # SFTæ•°æ®è´¨é‡é«˜ï¼Œé€šå¸¸ä¸éœ€è¦å¤§é‡æ¢¯åº¦ç´¯ç§¯
    # accumulation_steps=1 æ„å‘³ç€æ¯ä¸ªbatchéƒ½æ›´æ–°å‚æ•°
    parser.add_argument("--accumulation_steps", type=int, default=1, 
                       help="æ¢¯åº¦ç´¯ç§¯æ­¥æ•°ï¼ˆSFTé€šå¸¸è®¾ä¸º1ï¼‰")
    parser.add_argument("--grad_clip", type=float, default=1.0, 
                       help="æ¢¯åº¦è£å‰ªé˜ˆå€¼")
    parser.add_argument("--log_interval", type=int, default=100, 
                       help="æ—¥å¿—æ‰“å°é—´éš”")
    parser.add_argument("--save_interval", type=int, default=100, 
                       help="æ¨¡å‹ä¿å­˜é—´éš”")
    
    # ========== æ¨¡å‹æ¶æ„å‚æ•° ==========
    parser.add_argument('--hidden_size', default=512, type=int, 
                       help="éšè—å±‚ç»´åº¦")
    parser.add_argument('--num_hidden_layers', default=8, type=int, 
                       help="éšè—å±‚æ•°é‡")
    parser.add_argument('--max_seq_len', default=512, type=int, 
                       help="è®­ç»ƒçš„æœ€å¤§æˆªæ–­é•¿åº¦")
    parser.add_argument('--use_moe', default=0, type=int, choices=[0, 1], 
                       help="æ˜¯å¦ä½¿ç”¨MoEæ¶æ„ï¼ˆ0=å¦ï¼Œ1=æ˜¯ï¼‰")
    
    # ========== SFTæ•°æ®å’Œæ¢å¤å‚æ•° ==========
    # ğŸ“š SFTæ•°æ®è·¯å¾„çŸ¥è¯†ç‚¹
    # SFTæ•°æ®é€šå¸¸æ˜¯ç»“æ„åŒ–çš„é—®ç­”å¯¹æˆ–å¯¹è¯æ•°æ®
    # åŒ…å«instructionå’Œresponseä¸¤éƒ¨åˆ†
    parser.add_argument("--data_path", type=str, default="../dataset/sft_mini_512.jsonl", 
                       help="SFTè®­ç»ƒæ•°æ®è·¯å¾„")
    
    # ğŸ“š SFTæƒé‡ç»§æ‰¿çŸ¥è¯†ç‚¹
    # SFTé€šå¸¸ä»é¢„è®­ç»ƒæ¨¡å‹å¼€å§‹ï¼Œè€Œä¸æ˜¯ä»é›¶å¼€å§‹
    # 'pretrain'è¡¨ç¤ºä»é¢„è®­ç»ƒæƒé‡å¼€å§‹å¾®è°ƒ
    parser.add_argument('--from_weight', default='pretrain', type=str, 
                       help="åŸºäºå“ªä¸ªæƒé‡è®­ç»ƒï¼ˆé€šå¸¸ä»é¢„è®­ç»ƒæƒé‡å¼€å§‹ï¼‰")
    parser.add_argument('--from_resume', default=0, type=int, choices=[0, 1], 
                       help="æ˜¯å¦è‡ªåŠ¨æ£€æµ‹&ç»­è®­ï¼ˆ0=å¦ï¼Œ1=æ˜¯ï¼‰")
    
    # ========== å®éªŒè·Ÿè¸ª ==========
    parser.add_argument("--use_wandb", action="store_true", 
                       help="æ˜¯å¦ä½¿ç”¨wandb")
    parser.add_argument("--wandb_project", type=str, default="MiniMind-Full-SFT", 
                       help="wandbé¡¹ç›®å")
    
    args = parser.parse_args()

    # ========== 1. åˆå§‹åŒ–ç¯å¢ƒå’Œéšæœºç§å­ ==========
    local_rank = init_distributed_mode()
    if dist.is_initialized(): args.device = f"cuda:{local_rank}"
    setup_seed(42 + (dist.get_rank() if dist.is_initialized() else 0))
    
    # ========== 2. é…ç½®ç›®å½•ã€æ¨¡å‹å‚æ•°ã€æ£€æŸ¥ckp ==========
    os.makedirs(args.save_dir, exist_ok=True)
    lm_config = MokioMindConfig(hidden_size=args.hidden_size, num_hidden_layers=args.num_hidden_layers, use_moe=bool(args.use_moe))
    ckp_data = lm_checkpoint(lm_config, weight=args.save_weight, save_dir='../checkpoints') if args.from_resume==1 else None
    
    # ========== 3. è®¾ç½®æ··åˆç²¾åº¦ ==========
    device_type = "cuda" if "cuda" in args.device else "cpu"
    dtype = torch.bfloat16 if args.dtype == "bfloat16" else torch.float16
    autocast_ctx = nullcontext() if device_type == "cpu" else torch.cuda.amp.autocast(dtype=dtype)
    
    # ========== 4. é…wandb ==========
    wandb = None
    if args.use_wandb and is_main_process():
        import swanlab as wandb
        wandb_id = ckp_data.get('wandb_id') if ckp_data else None
        resume = 'must' if wandb_id else None
        wandb_run_name = f"MiniMind-Full-SFT-Epoch-{args.epochs}-BatchSize-{args.batch_size}-LearningRate-{args.learning_rate}"
        wandb.init(project=args.wandb_project, name=wandb_run_name, id=wandb_id, resume=resume)
    
    # ========== 5. å®šä¹‰æ¨¡å‹ã€æ•°æ®ã€ä¼˜åŒ–å™¨ ==========
    model, tokenizer = init_model(lm_config, args.from_weight, device=args.device)
    train_ds = SFTDataset(args.data_path, tokenizer, max_length=args.max_seq_len)
    train_sampler = DistributedSampler(train_ds) if dist.is_initialized() else None
    scaler = torch.cuda.amp.GradScaler(enabled=(args.dtype == 'float16'))
    optimizer = optim.AdamW(model.parameters(), lr=args.learning_rate)
    
    # ========== 6. ä»ckpæ¢å¤çŠ¶æ€ ==========
    start_epoch, start_step = 0, 0
    if ckp_data:
        model.load_state_dict(ckp_data['model'])
        optimizer.load_state_dict(ckp_data['optimizer'])
        scaler.load_state_dict(ckp_data['scaler'])
        start_epoch = ckp_data['epoch']
        start_step = ckp_data.get('step', 0)
    
    # ========== 7. DDPåŒ…æ¨¡å‹ ==========
    if dist.is_initialized():
        model._ddp_params_and_buffers_to_ignore = {"freqs_cos", "freqs_sin"}
        model = DistributedDataParallel(model, device_ids=[local_rank])
    
    # ========== 8. å¼€å§‹è®­ç»ƒ ==========
    for epoch in range(start_epoch, args.epochs):
        train_sampler and train_sampler.set_epoch(epoch)
        if epoch == start_epoch and start_step > 0: # ç¬¬ä¸€ä¸ªepochä¸”å­˜åœ¨æ£€æŸ¥ç‚¹
            batch_sampler = SkipBatchSampler(train_sampler or range(len(train_ds)), args.batch_size, start_step + 1)
            loader = DataLoader(train_ds, batch_sampler=batch_sampler, num_workers=args.num_workers, pin_memory=True)
            Logger(f'Epoch [{epoch + 1}/{args.epochs}]: è·³è¿‡å‰{start_step}ä¸ªstepï¼Œä»step {start_step + 1}å¼€å§‹')
            train_epoch(epoch, loader, len(loader) + start_step + 1, start_step, wandb)
        else: # é»˜è®¤ä»å¤´å¼€å§‹
            loader = DataLoader(train_ds, batch_size=args.batch_size, shuffle=(train_sampler is None), sampler=train_sampler, num_workers=args.num_workers, pin_memory=True)
            train_epoch(epoch, loader, len(loader), 0, wandb)
